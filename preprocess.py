# -*- coding: utf-8 -*-
"""Enron preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZlUgwpKjE2tURUGW6cfPp2aHPwREvoYc

# Clean dataset

## First round of cleaing
"""

import re, hashlib, pandas as pd
from pathlib import Path
from urllib.parse import unquote

IN_PATH  = Path("Emails.parquet")
OUT_PATH = Path("Emails_clean.parquet")

ENRON_DOMAIN = "enron.com"
MASS_MAIL_THRESHOLD = 15

email_re = re.compile(r'[\w\.\+\-/%]+@[\w\.\-]+\.\w+')

def norm_addr(s: str) -> str:
    if not s: return ""
    s = s.strip()
    # Extract email inside display names: "Name <x@y>" -> x@y
    m = email_re.search(s)
    addr = m.group(0) if m else s
    addr = addr.strip().lower()
    addr = addr.replace("mailto:", "")
    addr = unquote(addr)
    # Strip surrounding < >
    addr = addr.strip("<>").strip()
    return addr

def norm_addr_list(addr_list):
    out_data = []
    for x in addr_list:
        a = norm_addr(x)
        if a:
            out_data.append(a)
    return out_data

def simple_bodyhash(row):
    key = f"{row.get('from_raw','')}|{row.get('subject','')}|{row.get('dt_utc','')}|{(row.get('body_raw','') or '')[:200]}"
    return hashlib.md5(key.encode("utf-8")).hexdigest()

def main():
    OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    df = pd.read_parquet(IN_PATH)

    df["_bodyhash"] = df.apply(simple_bodyhash, axis=1)
    # Create a dedupe key preferring msg_id
    #dedupe_key = df["msg_id"].fillna("") + "|" + df["_bodyhash"]
    #df = df.loc[~dedupe_key.duplicated()].copy()
    df = df.drop_duplicates(subset="_bodyhash").copy()

    # Sender normalization -> person_id
    df["from_norm"] = df["from_raw"].fillna("").map(norm_addr)
    df["person_id"] = df["from_norm"]  # for now, use normalized sender email as ID

    # Recipients normalization
    df["to_norm"]  = df["to_list"].map(norm_addr_list)
    df["cc_norm"]  = df["cc_list"].map(norm_addr_list)
    df["bcc_norm"] = df["bcc_list"].map(norm_addr_list)

    # Recipient count & flags
    df["recipient_count"] = (df["to_norm"].map(len).fillna(0)
                            + df["cc_norm"].map(len).fillna(0)
                            + df["bcc_norm"].map(len).fillna(0)).astype("int32")
    df["domain_sender"]   = df["from_norm"].map(lambda a: a.split("@")[-1] if "@" in a else "")
    df["internal_sender"] = (df["domain_sender"] == ENRON_DOMAIN)
    df["mass_mail"]       = df["recipient_count"] >= MASS_MAIL_THRESHOLD
    df["path"] = df["path"].str.replace(r".*maildir[\\/]", "", regex=True)

    # Keep only B-schema columns
    keep = [
        "email_id","person_id","from_norm","to_norm","cc_norm","bcc_norm",
        "recipient_count","dt_utc","subject","body_raw",
        "internal_sender","mass_mail","domain_sender",
        "employee_dir","folder","path"
    ]
    out = df[keep].copy()
    out["dt_utc"] = pd.to_datetime(out["dt_utc"], utc=True)

    out.to_parquet(OUT_PATH, index=False)
    print(f"Wrote {len(out):,} rows to {OUT_PATH}")

if __name__ == "__main__":
    main()

"""## Recheck data post-cleaning"""

import re, hashlib, pandas as pd
from pathlib import Path
from urllib.parse import unquote


IN_PATH  = Path("Emails_clean.parquet")      # from A
OUT_PATH = Path("Emails_clean.parquet")

#OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
df = pd.read_parquet(IN_PATH)
email_re = re.compile(r'^[\w\.\+\-/%]+@[\w\.\-]+\.\w+$')

weird_from = df.loc[~df["from_norm"].fillna("").str.match(email_re), "from_norm"]

print("Weird from_raw count:", len(weird_from))
print("Examples:\n", weird_from.sample(3, random_state=1))

print("\n")

print("Normalized recipients first 5 items to list:")
print(df["to_norm"].head(5).tolist())
print(type(df["to_norm"].iloc[0]))

print("\n")

empty_recips = df[df["recipient_count"] == 0]
print("Emails with 0 recipients:", len(empty_recips))

print("\n")

print("Null dates:", df["dt_utc"].isna().sum())
print("\n")

print(df["recipient_count"].describe())
print("Mass mails:", df["mass_mail"].sum())
print("\n")

print("Emails with empty body:", (df["body_raw"].str.strip() == "").sum())

